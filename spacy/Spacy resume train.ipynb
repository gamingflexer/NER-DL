{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGIbT0uduP_l"
      },
      "outputs": [],
      "source": [
        "!pip install textract -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rOJ7wTz1UsOJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(file):\n",
        "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    return (data)\n",
        "\n",
        "def write_data(file, data):\n",
        "    with open (file, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "        \n",
        "def pickle_load(file):\n",
        "    \n",
        "    data = pickle.load(open(file,'rb'))\n",
        "    return data\n",
        "\n",
        "data = load_data(\"700data_3.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RrbQr53RUsOK"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "ner=nlp.get_pipe(\"ner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yGhrY0maUsOK"
      },
      "outputs": [],
      "source": [
        "# Adding labels to the `ner`\n",
        "\n",
        "for _, annotations in data:\n",
        "  for ent in annotations.get(\"entities\"):\n",
        "    ner.add_label(ent[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jS2EY5MaUsOK"
      },
      "outputs": [],
      "source": [
        "# Disable pipeline components you dont need to change\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE0FIuuqUsOL",
        "outputId": "4b25c38f-faca-4acd-a9da-5eac67c0aaf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Losses {'ner': 222174.5624575764}\n"
          ]
        }
      ],
      "source": [
        "# Import requirements\n",
        "import random\n",
        "from spacy.util import minibatch, compounding\n",
        "from pathlib import Path\n",
        "\n",
        "# TRAINING THE MODEL\n",
        "with nlp.disable_pipes(*unaffected_pipes):\n",
        "\n",
        "  # Training for 30 iterations\n",
        "  for iteration in range(1):\n",
        "\n",
        "    # shuufling examples  before every iteration\n",
        "    random.shuffle(data)\n",
        "    losses = {}\n",
        "    # batch up the examples using spaCy's minibatch\n",
        "    batches = minibatch(data, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        nlp.update(\n",
        "                    texts,  # batch of texts\n",
        "                    annotations,  # batch of annotations\n",
        "                    drop=0.2,  # dropout - make it harder to memorise data\n",
        "                    losses=losses,\n",
        "                )\n",
        "    print(\"Losses\", losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_k-OxsTUsOL",
        "outputId": "9d178a2e-30ea-46c0-9cd2-56fd0b15abf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entities [('Vijayalakshmi Govindarajan', 'Name'), ('SAP as', 'Companies worked at'), ('SAP Basis -', 'Companies worked at')]\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(data[3][0])\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH07pMLUXg85",
        "outputId": "78751c23-4299-463e-9cb7-8151be7c685f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.3 MB/s \n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9p4vy1AWqRL",
        "outputId": "e44b9c72-cab1-4871-a1b8-17a1e3bd5438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------STARTING-------\n",
            "Losses {'ner': 286893.8657830385}\n",
            "Losses {'ner': 273688.8629359987}\n",
            "Losses {'ner': 271085.58670354635}\n",
            "Losses {'ner': 272182.9842940569}\n",
            "Losses {'ner': 269024.11262334883}\n",
            "Losses {'ner': 270455.4656434059}\n",
            "Losses {'ner': 266808.90157675743}\n",
            "Losses {'ner': 268779.64239776134}\n",
            "Losses {'ner': 267750.3622187376}\n",
            "Losses {'ner': 266806.4804009795}\n",
            "Losses {'ner': 267340.73468375206}\n",
            "Losses {'ner': 265742.1821196079}\n",
            "Losses {'ner': 267040.25214481354}\n",
            "Losses {'ner': 268229.3312683835}\n",
            "Losses {'ner': 267109.0554922819}\n",
            "Losses {'ner': 269100.0800716877}\n",
            "Losses {'ner': 265854.11294198036}\n",
            "Losses {'ner': 267282.1326575279}\n",
            "Losses {'ner': 266667.692186594}\n",
            "Losses {'ner': 265838.53541493416}\n",
            "Losses {'ner': 266207.21528328815}\n",
            "Losses {'ner': 266613.3947337866}\n",
            "Losses {'ner': 265761.3803472519}\n",
            "Losses {'ner': 266707.6562460512}\n",
            "Losses {'ner': 262798.4459848404}\n",
            "Losses {'ner': 264642.7012481466}\n",
            "Losses {'ner': 264651.99743089825}\n",
            "Losses {'ner': 268844.89882114343}\n",
            "Losses {'ner': 265417.68861436844}\n",
            "Losses {'ner': 264487.7838001251}\n"
          ]
        }
      ],
      "source": [
        "# Train NER from a blank spacy model\n",
        "import spacy\n",
        "import spacy\n",
        "# Importing requirements\n",
        "from spacy.util import minibatch, compounding\n",
        "import random\n",
        "\n",
        "tags_vals = ['Empty','UNKNOWN','Email Address', 'Links', 'Skills', 'Graduation Year', 'College Name', 'Degree', 'Companies worked at', 'Location', 'Name', 'Designation', 'projects', 'Years of Experience', 'Can Relocate to', 'Rewards and Achievements', 'Address', 'University', 'Relocate to', 'Certifications', 'state', 'links', 'College', 'training', 'des', 'abc']\n",
        "\n",
        "#spacy.prefer_gpu()\n",
        "nlp=spacy.load(\"en_core_web_sm\") \n",
        "\n",
        "# Getting the ner component\n",
        "ner=nlp.get_pipe('ner')\n",
        "\n",
        "# Add the new label to ner\n",
        "for i in tags_vals:\n",
        "  ner.add_label(i)\n",
        "\n",
        "# Resume training\n",
        "optimizer = nlp.resume_training()\n",
        "move_names = list(ner.move_names)\n",
        "\n",
        "# List of pipes you want to train\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "\n",
        "# List of pipes which should remain unaffected in training\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "\n",
        "# Begin training by disabling other pipeline components\n",
        "with nlp.disable_pipes(*other_pipes) :\n",
        "  print(\"------STARTING-------\")\n",
        "  sizes = compounding(1.0, 4.0, 1.001)\n",
        "  # Training for 30 iterations     \n",
        "  for itn in range(30):\n",
        "    # shuffle examples before training\n",
        "    random.shuffle(data)\n",
        "    # batch up the examples using spaCy's minibatch\n",
        "    batches = minibatch(data, size=sizes)\n",
        "    # ictionary to store losses\n",
        "    losses = {}\n",
        "    for batch in batches:\n",
        "      texts, annotations = zip(*batch)\n",
        "      # Calling update() over the iteration\n",
        "      nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
        "    print(\"Losses\", losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DyeKuhbOuPFO"
      },
      "outputs": [],
      "source": [
        "import textract\n",
        "import re\n",
        "\n",
        "text1 = str(textract.process('/content/content/Sayli Sunil Gaikwad_14625.pdf'))\n",
        "text1 = re.sub(\"\\n\",\"\",text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWHw7fI5Yeeu",
        "outputId": "686ac049-c6f3-4f86-c19a-51f04de835df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME                                    -b'\n",
            "DESIGNATION                             -Senior Test Engineer\n",
            "LOCATION                                -Mumbai\n",
            "LOCATION                                -Mumbai\n",
            "LOCATION                                -Mumbai\n",
            "DESIGNATION                             -Senior Test Engineer\n",
            "LOCATION                                -Mumbai\n",
            "LOCATION                                -Mumbai\n",
            "LOCATION                                -Mumbai\n"
          ]
        }
      ],
      "source": [
        "doc = nlp(text1)\n",
        "for ent in doc.ents:\n",
        "    print(f'{ent.label_.upper():{40}}-{ent.text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc-O9KdBvPm0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zoY_lTTLZ_2p"
      },
      "outputs": [],
      "source": [
        "nlp.to_disk(\"/tensorflow-1.15.2/new_30_resume_trains\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAHZGgaQrIBS"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/new.zip /content/content/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBHSmUWQunio"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Spacy_resume_train.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
